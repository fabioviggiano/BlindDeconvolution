Analisi e Interpretazione dei Risultati
Questa tabella ora ci permette di trarre delle conclusioni chiare e basate sui dati, esattamente come richiesto in un progetto di ricerca.
1. Conferma Totale del Feedback del Professore
Confrontando T01 (PSNR: 12.92) con T02 (PSNR: 23.32), si dimostra quantitativamente l'impatto del suggerimento del professore. Passare da un blur "esagerato" a uno "realistico" ha quasi raddoppiato il PSNR e ha portato l'SSIM da un valore pessimo (0.06) a uno buono (0.68). Questa è la prova più forte che la direzione presa è quella giusta.
2. Chiara Degradazione delle Performance con l'Aumentare del Blur
La tendenza è inequivocabile. Seguendo i test sistematici, vediamo che:
Blur Leggero (T02, T04, T05): PSNR è costantemente sopra i 21 dB. L'algoritmo funziona molto bene.
Blur Moderato (T06, T07): Le performance crollano. Il motion blur (T06) si difende con un PSNR di 18.21 dB, ma il gaussian blur (T07) crolla a 12.71 dB, un risultato quasi inutilizzabile.
Blur Intenso (T08-T13): I risultati sono molto variabili, ma generalmente bassi. È interessante notare come il motion blur con len=30 (T08) dia un risultato sorprendentemente buono (PSNR 22.13), forse a causa di una combinazione fortunata di parametri, ma in generale i valori si assestano sotto i 20 dB.
3. Sensibilità al Tipo di Blur: il Gaussiano è più "difficile"
Confrontando test a parità di livello, emerge un pattern:
Leggero: Motion (T04, PSNR 22.63) vs Gaussian (T05, PSNR 21.67) -> Performance simili.
Moderato: Motion (T06, PSNR 18.21) vs Gaussian (T07, PSNR 12.71) -> Il blur gaussiano è molto più dannoso.
Questo suggerisce che l'algoritmo, basato su gradienti, soffre particolarmente la distruzione diffusa e omogenea dei dettagli causata da un blur gaussiano di media-alta intensità.
4. L'Importanza della Dimensione del Kernel di Stima
Il confronto tra T09 (kernel_size: 35) e T12 (kernel_size: 61) per lo stesso identico blur (motion_len=30) è illuminante. Aumentare lo spazio di ricerca del kernel in modo eccessivo (T12) ha peggiorato i risultati (PSNR da 19.30 a 17.62), confermando l'ipotesi che dare troppo spazio all'algoritmo può portarlo a introdurre rumore o a stimare un kernel meno preciso.
Prossimi Passi
Hai completato in modo eccellente e approfondito la prima parte del progetto. Ora hai una solida baseline quantitativa sul comportamento dell'algoritmo di Shan.
Il prossimo passo è chiaro:
Passare all'implementazione della rete neurale (U-Net).
Con questa tabella, avrai un potente strumento di confronto per dimostrare dove e quanto l'approccio end-to-end supervisionato supererà (o forse no!) il metodo model-based. La previsione del tuo professore è che le reti neurali si comporteranno meglio proprio sui casi di blur più intenso, dove l'algoritmo di Shan ha mostrato le maggiori difficoltà (es. T07, T11, T13).